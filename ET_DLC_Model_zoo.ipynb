{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302f30c0-0ccc-4e5e-b5de-81aa00c5dcca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import deeplabcut\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from datetime import date\n",
    "import math\n",
    "\n",
    "# Converting .mov videos to .mp4\n",
    "def conv_mp4(input_file):\n",
    "    out_name = os.path.splitext(input_file)[0].lstrip('.') \n",
    "    print(out_name)\n",
    "    output_file = out_name + '.mp4'\n",
    "\n",
    "    # Run FFmpeg command to convert MOV to MP4\n",
    "    command = f\"ffmpeg -i {input_file} -c:v libx264 -preset medium -crf 23 -c:a aac -b:a 128k {output_file}\"\n",
    "    subprocess.call(command, shell=True)\n",
    "    new = os.path.join(os.path.dirname(os.path.dirname(output_file)), 'Conv_vids', os.path.basename(output_file))\n",
    "    shutil.move(output_file, new)\n",
    "\n",
    "\n",
    "def downsize(path, to_path):\n",
    "    dsv = deeplabcut.DownSampleVideo(path, width=320, height=240)\n",
    "    shutil.move(dsv, os.path.join(to_path, os.path.basename(dsv)))\n",
    "\n",
    "#cropping video and Gamma correction\n",
    "def gamma_correct(convid):\n",
    "    \n",
    "    # Load the video file\n",
    "    video = cv2.VideoCapture(convid)\n",
    "\n",
    "    # Get the frame rate and total number of frames\n",
    "    fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    #*********************************************\n",
    "    # Set appropriate values for target average illumination of the frame\n",
    "    target_br = 0.6\n",
    "\n",
    "    #**********************************************\n",
    "    \n",
    "    target_g = math.log(target_br)\n",
    "    \n",
    "    # Set the video writer\n",
    "    output_name = os.path.splitext(os.path.basename(convid))[0].lstrip('.') + '_AGC.mp4'\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_name, fourcc, fps, (int(video.get(cv2.CAP_PROP_FRAME_WIDTH)), int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "    start_frame = 0\n",
    "    \n",
    "    # Set the current frame number to the start frame\n",
    "    video.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "    frame_number = start_frame\n",
    "    \n",
    "    # Loop through the frames and write them to the output video\n",
    "    for i in range(start_frame, total_frames):\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Normalize the pixel values to the range [0, 1]\n",
    "        frame_normalized = frame.astype(np.float32) / 255.0\n",
    "        gray = cv2.cvtColor(frame_normalized, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Finding the mean luminance of the frame\n",
    "        brightness = np.mean(frame_normalized)\n",
    "\n",
    "        #finding and correcting gamma - a number is assigned to be the 'innate' gamma value of the frame, and that value is used to find the correction needed. \n",
    "        if brightness == 0:\n",
    "            print('err')\n",
    "            continue\n",
    "        assigned_g = math.log(brightness)\n",
    "        gamma = assigned_g/target_g\n",
    "\n",
    "        # Apply gamma correction\n",
    "        frame_corrected = np.power(frame_normalized, 1/gamma)\n",
    "\n",
    "        # Scale the pixel values back to the range [0, 255]\n",
    "        frame_scaled = (frame_corrected * 255.0).astype(np.uint8)\n",
    "        \n",
    "        print(round(frame_number/total_frames*100, 2), end = '\\r')\n",
    "        frame_number += 1\n",
    "        # cv2.imshow('output', frame)\n",
    "        # cv2.imshow('output', frame_scaled)\n",
    "        out.write(frame_scaled)\n",
    "    # new = os.path.join(os.path.dirname(os.path.dirname(convid)), 'GC_Conv_vids', os.path.basename(convid))\n",
    "    # shutil.move(dsv, new)\n",
    "    print(\"Done - \", convid)\n",
    "    print('')\n",
    "    # Release the video objects\n",
    "    video.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "#cropping video and Gamma correction\n",
    "def adap_gamma_correct(convid, tbr, clp, gs):\n",
    "    \n",
    "    # Load the video file\n",
    "    video = cv2.VideoCapture(convid)\n",
    "\n",
    "    # Get the frame rate and total number of frames\n",
    "    fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "    # fps = 30\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(total_frames)\n",
    "\n",
    "    #*********************************************\n",
    "\n",
    "    target_br = tbr\n",
    "    target_g = math.log(target_br)\n",
    "\n",
    "    gs_w, gs_h = gs\n",
    "\n",
    "    #**********************************************\n",
    "\n",
    "    # Set the video writer\n",
    "    output_name = os.path.splitext(os.path.basename(convid))[0].lstrip('.') + '_' + str(int(target_br*100)) + '_' + str(clp) + '_' + str(gs_w) + '_' + str(gs_h) + '_AGC_clahe.mp4'\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_name, fourcc, fps, (int(video.get(cv2.CAP_PROP_FRAME_WIDTH)), int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "    start_frame = 0\n",
    "    \n",
    "    # Set the current frame number to the start frame\n",
    "    video.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "    frame_number = 0\n",
    "    \n",
    "    # Loop through the frames and write them to the output video\n",
    "    for i in range(start_frame, total_frames):\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)\n",
    "                \n",
    "        clahe = cv2.createCLAHE(clipLimit=clp, tileGridSize=(gs_w, gs_h))\n",
    "        lab[...,0] = clahe.apply(lab[...,0])\n",
    "        \n",
    "        frame_scaled_edt = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "        \n",
    "        \n",
    "        frame_normalized = frame_scaled_edt.astype(np.float32) / 255.0\n",
    "        gray = cv2.cvtColor(frame_normalized, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        brightness = np.mean(frame_normalized)\n",
    "        \n",
    "        #finding and correcting gamma - a number is assigned to be the 'innate' gamma value of the frame, and that value is used to find the correction needed. \n",
    "        if brightness == 0:\n",
    "            # cv2.imshow('output', frame)\n",
    "            print(brightness, ' - err')\n",
    "            continue\n",
    "        assigned_g = math.log(brightness)\n",
    "        gamma = assigned_g/target_g\n",
    "        \n",
    "        # Apply gamma correction\n",
    "        frame_corrected = np.power(frame_normalized, 1/gamma)\n",
    "\n",
    "        # Scale the pixel values back to the range [0, 255]\n",
    "        frame_scaled = (frame_corrected * 255.0).astype(np.uint8)        \n",
    "\n",
    "        progress = frame_number/total_frames*100\n",
    "        print(round(progress, 2), noted, end = '\\r')\n",
    "        frame_number += 1\n",
    "\n",
    "        out.write(frame_scaled)\n",
    "    video.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Done - \", convid)\n",
    "    print('')\n",
    "\n",
    "\n",
    "#Processing videos using DeepLabCut ModelZoo's pretrained model - Primate face\n",
    "def process(fold, project_name, your_name):\n",
    "    file = fold[0]\n",
    "    print(file)\n",
    "    bodyparts = ['RightEye_Outer', 'RightEye_Top', 'RightEye_Bottom', 'RightEye_Inner', 'RightEye_Pupil', 'LeftEye_Outer', 'LeftEye_Top', 'LeftEye_Bottom', 'LeftEye_Inner', 'LeftEye_Pupil',\n",
    "                 'OutlineTop_Mid','RightNostrils_Top', 'RightNostrils_Bottom','LeftNostrils_Top', 'LeftNostrils_Bottom']\n",
    "    videotype = os.path.splitext(file)[-1].lstrip('.')  # or MOV, or avi, whatever you uploaded!\n",
    "    video_down = folder\n",
    "    name_fold = 'Analyse_' + os.path.basename(os.path.dirname(file))\n",
    "    \n",
    "    model_options = deeplabcut.create_project.modelzoo.Modeloptions\n",
    "    model_selection = 'primate_face'\n",
    "\n",
    "    config_path, train_config_path = deeplabcut.create_pretrained_project(\n",
    "        project_name,\n",
    "        your_name,\n",
    "        video_down,\n",
    "        videotype=videotype,\n",
    "        model=model_selection,\n",
    "        analyzevideo=True,\n",
    "        createlabeledvideo=False,\n",
    "        copy_videos=False,\n",
    "    )\n",
    "\n",
    "    edits = {\n",
    "        'dotsize': 1.5,  # size of the dots!--------------------------------------------------------------------------------------------------------------------------------\n",
    "        'pcutoff': 0.4,  # the higher, the more conservative the plotting!\n",
    "    }\n",
    "    deeplabcut.auxiliaryfunctions.edit_config(config_path, edits)\n",
    "    project_path = os.path.dirname(config_path)\n",
    "    full_video_path = []\n",
    "    for i in fold:\n",
    "        full_video_path.append(os.path.join(project_path,'videos', os.path.basename(i)))\n",
    "\n",
    "    # filter predictions (should already be done above ;):\n",
    "    deeplabcut.filterpredictions(config_path, full_video_path, videotype=videotype)\n",
    "\n",
    "    # re-create the video with your edits!\n",
    "    # deeplabcut.CropVideo(config_path, full_video_path, 'crop', \n",
    "    deeplabcut.create_labeled_video(config_path, full_video_path, videotype=videotype, displayedbodyparts=bodyparts, draw_skeleton = True, filtered=True)\n",
    "\n",
    "#Cropping the video based on confidence of facial features\n",
    "def crop_it(feed):\n",
    "    \n",
    "    fl_pth, vid_pth, x = feed\n",
    "    # deeplabcut.analyze_videos(config_path, 'CropGr.mp4', save_as_csv=True, dynamic=(True,.6,30))\n",
    "    print(\"Starting Cropping\")\n",
    "\n",
    "    # Load tracking results generated by DeepLabCut\n",
    "    tracking_data = pd.read_hdf(fl_pth)\n",
    "\n",
    "    # Define the names of the facial features that you want to extract frames for\n",
    "    feature_names = ['RightEye_Pupil','LeftEye_Pupil', 'NostrilsTop_Centre', 'OutlineTop_Mid']\n",
    "\n",
    "    # Define the threshold for the confidence score of the facial features\n",
    "    confidence_threshold = 0.9\n",
    "    \n",
    "    # Load the input video\n",
    "    cap = cv2.VideoCapture(vid_pth)\n",
    "    \n",
    "    tot_frame = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Define the output video writer\n",
    "    bn = os.path.basename(vid_pth).split('.')[0]\n",
    "    out_file = 'Crpoutput_video' + bn + '.mp4'\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(out_file, fourcc, 30, (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "    print(\"Output file written - \", out_file)\n",
    "\n",
    "    # Loop through the video frames and extract frames with facial features\n",
    "    frame_number = 0\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            # Get the tracking data for the current frame\n",
    "            frame_data = tracking_data.loc[frame_number]\n",
    "\n",
    "            # Check if the desired facial features are present in the frame\n",
    "            feature_present = False\n",
    "            check = 0\n",
    "            for feature_name in feature_names:\n",
    "                if feature_name in frame_data.loc[x] and frame_data.loc[x].loc[feature_name].loc['likelihood'] > confidence_threshold:\n",
    "                    check += 1\n",
    "            if check==4:\n",
    "                feature_present = True\n",
    "\n",
    "            # If the desired facial features are present, save the frame to the output video\n",
    "            if feature_present: #check==4\n",
    "                # cv2.imshow('output', frame)\n",
    "                out.write(frame)\n",
    "            # Display the output\n",
    "            #cv2.imshow('output', frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            print(round(frame_number/tot_frame*100, 2), end = '\\r')\n",
    "            # Increment the frame number\n",
    "            frame_number += 1\n",
    "        else:\n",
    "            break\n",
    "    print(\"Done\")\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def main():\n",
    "    #enter path of folder (including folder name) containing all your videos of interest------------------------------------------------------------------------------------------\n",
    "    vid_dir = '/home/yramakrishna/DeepLabCut/conda-environments/Videos'\n",
    "    #initializing project name and author's name ---------------------------------------------------------------------------------------------------------------------------------\n",
    "    project_name = 'DLC'\n",
    "    your_name = 'YR'\n",
    "    \n",
    "    os.chdir(os.path.dirname(vid_dir))\n",
    "    print(os.getcwd())\n",
    "    \n",
    "    #Create a new folder called All_vids in the current directory\n",
    "    if not os.path.exists('All_vids'):\n",
    "            os.makedirs('All_vids')\n",
    "    os.chdir('All_vids')\n",
    "    \n",
    "    to_dir = os.path.join(os.getcwd(), os.path.basename(vid_dir)) #moving the folderwith videos to the current directory\n",
    "    shutil.move(vid_dir, to_dir)\n",
    "    \n",
    "    #Storing converted videos in a new folder\n",
    "    if not os.path.exists('Conv_vids'):\n",
    "            os.makedirs('Conv_vids')\n",
    "            \n",
    "    \n",
    "    #Converting files from mov to MP4 (if any)\n",
    "    for file in os.listdir(os.path.join(os.path.dirname(to_dir), 'Videos')):\n",
    "        path=os.path.join(os.path.join(os.path.dirname(to_dir), 'Videos', file))\n",
    "        if file.endswith(\".mov\"):\n",
    "            conv_mp4(path)\n",
    "        elif file.endswith(\".mp4\"):\n",
    "            path2=os.path.join(os.path.join(os.path.dirname(to_dir), 'Conv_vids', file))\n",
    "            shutil.copy(path, path2)\n",
    "    \n",
    "    os.chdir(os.path.dirname(to_dir))\n",
    "    \n",
    "    if not os.path.exists('Downsize_Conv_vids'):\n",
    "            os.makedirs('Downsize_Conv_vids')\n",
    "    os.chdir('Downsize_Conv_vids')\n",
    "    \n",
    "    # vid_names = []\n",
    "    for file in os.listdir(os.path.join(os.path.dirname(to_dir), 'Conv_vids')):\n",
    "        if file.endswith(\".mp4\"):\n",
    "            path=os.path.join(os.path.join(os.path.dirname(to_dir), 'Conv_vids', file))\n",
    "            downsize(path, os.getcwd())\n",
    "    \n",
    "    os.chdir(os.path.dirname(to_dir))\n",
    "    \n",
    "    #Creae a folder for gamma corrected videos\n",
    "    if not os.path.exists('AGC_Conv_vids'):\n",
    "            os.makedirs('AGC_Conv_vids')\n",
    "    os.chdir('AGC_Conv_vids')\n",
    "    \n",
    "    #Applying adaptive gamma correction with CLAHE on the mp4 videos\n",
    "    for file in os.listdir(os.path.join(os.path.dirname(to_dir), 'Downsize_Conv_vids')):\n",
    "        if file.endswith(\".mp4\"):\n",
    "            path=os.path.join(os.path.join(os.path.dirname(to_dir), 'Downsize_Conv_vids', file))\n",
    "            gamma_correct(path)\n",
    "            video = cv2.VideoCapture(path)\n",
    "            width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            tbr = 0.72\n",
    "            clp = 2\n",
    "            gs_w = int(width / 64.0)\n",
    "            gs_h = int(height / 48.0)\n",
    "            gs = [gs_w, gs_h]\n",
    "            adap_gamma_correct(path, tbr, clp, gs)\n",
    "            \n",
    "    os.chdir('..')\n",
    "    \n",
    "    #Compiling a list ofpaths for analysis\n",
    "    folder = [] \n",
    "    for file in os.listdir(os.path.join(os.path.dirname(to_dir), 'AGC_Conv_vids')):\n",
    "        if file.endswith(\".mp4\"):\n",
    "            path=os.path.join(os.path.join(os.path.dirname(to_dir), 'AGC_Conv_vids', file))\n",
    "            folder.append(path)\n",
    "    \n",
    "    #Analyzing all videos with ModelZoo\n",
    "    process(folder, project_name, your_name)\n",
    "    \n",
    "    #Collecting files with information on labels, as well as the labelled videos.\n",
    "    os.chdir(os.path.join(os.getcwd()))\n",
    "    h5files = []\n",
    "    vid_to_crop = []\n",
    "    today = str(date.today())\n",
    "    # today = \"2023-04-12\" -------------------------------------------------Modify if you created the modelzoo files on a different day than today.\n",
    "    proj_fold = project_name+'-'+your_name+'-'+today\n",
    "    target = os.path.join(os.getcwd(),proj_fold,'videos')\n",
    "    for file in os.listdir(target):\n",
    "        if file.endswith(\"filtered.h5\"):\n",
    "            h5files.append(os.path.join(target,file))\n",
    "    for file in os.listdir(target):   \n",
    "        if file.endswith(\"labeled.mp4\"):\n",
    "            vid_to_crop.append(os.path.join(target,file))\n",
    "    \n",
    "    \n",
    "    os.chdir(os.path.join(os.getcwd()))\n",
    "    if not os.path.exists('Cropped_vids'):\n",
    "            os.makedirs('Cropped_vids')\n",
    "    os.chdir('Cropped_vids')\n",
    "    \n",
    "    crop_source = []\n",
    "    \n",
    "    if len(h5files)==len(vid_to_crop):\n",
    "        for i in h5files:\n",
    "            found = ''\n",
    "            for j in vid_to_crop:\n",
    "                x = os.path.splitext(i)[0].rstrip('_filtered.h5')\n",
    "                y = os.path.splitext(j)[0].rstrip('filtered_labeled.mp4')\n",
    "                if x==y:\n",
    "                    found = j\n",
    "            k = os.path.basename(i)\n",
    "            l = 'DLC' + k.split('DLC')[1] + 'DLC' + k.split('DLC')[2].rstrip('_filtered.h5')\n",
    "            crop_source.append([i,found, l])\n",
    "    \n",
    "    c_s = np.array(crop_source)\n",
    "    \n",
    "    all_frames = []\n",
    "    \n",
    "    for i in c_s:\n",
    "        x = crop_it(i)\n",
    "        all_frames.append([i[1],x])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
